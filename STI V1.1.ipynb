{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:56:03.551852700Z",
     "start_time": "2023-09-13T15:56:03.535854800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import shutil\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications import efficientnet as efn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from scipy.spatial.distance import squareform\n",
    "%matplotlib inline\n",
    "from toolz import interleave\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n",
      "N_REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', TPU.master())\n",
    "except ValueError:\n",
    "    print('Running on GPU')\n",
    "    TPU = None\n",
    "\n",
    "if TPU:\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    strategy = tf.distribute.TPUStrategy(TPU)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "N_REPLICAS = strategy.num_replicas_in_sync\n",
    "# Number of computing cores, is 8 for a TPU V3-8\n",
    "print(f'N_REPLICAS: {N_REPLICAS}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T13:03:33.361184300Z",
     "start_time": "2023-09-13T13:03:33.337185300Z"
    }
   },
   "id": "58e3080e72ae46d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![ploidy support](./assets/ploidy.jpg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class DataReader:\n",
    "    \"\"\"\n",
    "    If the reference is unphased, cannot handle phased target data, so the valid (ref, target) combinations are:\n",
    "    (phased, phased), (phased, unphased), (unphased, unphased) \n",
    "    If the reference is haps, the target cannot be unphased (can we merge every two haps to form unphased diploids?)\n",
    "    Important note: for each case, the model should be trained separately\n",
    "    \"\"\"\n",
    "    def __init__(self, ):\n",
    "        self.allele_count = 2\n",
    "        self.genotype_vals = None\n",
    "        self.ref_is_phased = None\n",
    "        self.reference_panel = None\n",
    "        self.VARIANT_COUNT = 0\n",
    "        self.is_phased = False\n",
    "        self.MISSING_VALUE = None\n",
    "        self.ref_is_hap = False\n",
    "        self.target_is_hap = False\n",
    "        self.ref_n_header_lines = []\n",
    "        self.ref_n_data_header = \"\"\n",
    "        self.target_n_header_lines = []\n",
    "        self.target_n_data_header = \"\"\n",
    "        self.map_values_1_vec = np.vectorize(self.map_hap_2_ind_parent_1)\n",
    "        self.map_values_2_vec = np.vectorize(self.map_hap_2_ind_parent_2)\n",
    "        self.delimiter_dictionary = {\"vcf\":\"\\t\", \"csv\":\",\", \"tsv\":\"\\t\", \"infer\":\"\\t\"}\n",
    "        self.training_file_extension = \"vcf\"\n",
    "        self.test_file_extension = \"vcf\"\n",
    "        self.target_is_phased = True\n",
    "        \n",
    "    def read_star_sv_files(self, file_path, is_reference=False, separator=\"\\t\", first_column_is_index=True, comments=\"##\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        In this form the data should not have more than a column for ids. The first column can be either sample ids or variant ids. In case of latter, make sure to pass :param variants_as_columns=True. Example of sample input file:\n",
    "        ## Comment line 0\n",
    "        ## Comment line 1\n",
    "        Sample_id 17392_chrI_17400_T_G ....\n",
    "        HG1023               1\n",
    "        HG1024               0\n",
    "        \"\"\"\n",
    "        print(\"Reading the file...\")\n",
    "        data_header = None\n",
    "        root, ext = os.path.splitext(file_path)\n",
    "        with gzip.open(file_path, 'rt') if ext in {'.gz', '.zip'} else open(file_path, 'rt') as f_in:\n",
    "            # skip info\n",
    "            while True:\n",
    "                line = f_in.readline()\n",
    "                if line.startswith(comments):\n",
    "                    if is_reference:\n",
    "                        self.ref_n_header_lines.append(line)\n",
    "                    else:\n",
    "                        self.target_n_header_lines.append(line)\n",
    "                else:\n",
    "                    data_header = line\n",
    "                    break\n",
    "        if data_header is None:\n",
    "            raise IOError(\"The file only contains comments!\")\n",
    "        df = pd.read_csv(file_path,\n",
    "                           sep=separator,\n",
    "                           comment=comments[0],\n",
    "                           index_col=0 if first_column_is_index else None,\n",
    "                           dtype='category',\n",
    "                           names=data_header.strip().split(separator))\n",
    "        df = df.astype('category')\n",
    "        return df\n",
    "\n",
    "\n",
    "    def find_file_extension(self, file_path, file_format, delimiter):\n",
    "        # Default assumption\n",
    "        separator = \"\\t\"\n",
    "        found_file_format = \"vcf\"\n",
    "        \n",
    "        if file_format not in {\"vcf\", \"csv\", \"tsv\", \"infer\"}:\n",
    "            raise ValueError(\"File extension must be one of {'vcf', 'csv', 'tsv', 'infer'}.\")\n",
    "        if file_format == 'infer':\n",
    "            file_name_tokenized = file_path.split(\".\")\n",
    "            for possible_extension in file_name_tokenized[::-1]:\n",
    "                if possible_extension in {\"vcf\", \"csv\", \"tsv\"}:\n",
    "                    found_file_format = possible_extension\n",
    "                    separator = self.delimiter_dictionary[possible_extension] if delimiter is not None else delimiter\n",
    "                    break\n",
    "        else:\n",
    "            found_file_format = file_format\n",
    "            \n",
    "        return found_file_format, separator\n",
    "\n",
    "    \n",
    "    def assign_training_set(self, file_path,\n",
    "                            target_is_gonna_be_phased_or_haps,\n",
    "                            variants_as_columns=False,\n",
    "                            delimiter=None,\n",
    "                            file_format=\"infer\",\n",
    "                            first_column_is_index=True,\n",
    "                            comments=\"##\") -> None:\n",
    "        \"\"\"\n",
    "        :param file_path: reference panel or the training file path. Currently, VCF, CSV, and TSV are supported\n",
    "        :param target_is_gonna_be_phased: Indicates whether the targets for the imputation will be phased or unphased.\n",
    "        :param variants_as_columns: Whether the columns are variants and rows are samples or vice versa.\n",
    "        :param delimiter: the seperator used for the file\n",
    "        :param file_format: one of {\"vcf\", \"csv\", \"tsv\", \"infer\"}. If \"infer\" then the class will try to find the extension using the file name.\n",
    "        :param first_column_is_index: used for csv and tsv files to indicate if the first column should be used as identifier for samples/variants.\n",
    "        :param comments: The token to be used to filter out the lines indicating comments.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.target_is_phased = target_is_gonna_be_phased_or_haps\n",
    "        sample_value_index = 2\n",
    "        self.training_file_extension, separator = self.find_file_extension(file_path, file_format, delimiter)\n",
    "\n",
    "        self.reference_panel = self.read_star_sv_files(file_path, is_reference=True, separator=separator, first_column_is_index=first_column_is_index, comments=comments) if self.training_file_extension != 'vcf' else self.read_star_sv_files(file_path, is_reference=True, separator='\\t', first_column_is_index=False, comments=\"##\")\n",
    "        \n",
    "        if self.training_file_extension != \"vcf\":\n",
    "            if variants_as_columns:\n",
    "                self.reference_panel = self.reference_panel.transpose()\n",
    "            self.reference_panel.reset_index(inplace=True)\n",
    "            self.reference_panel.rename(columns={self.reference_panel.columns[0]: \"ID\"}, inplace=True)\n",
    "        else: # VCF\n",
    "            sample_value_index += 8\n",
    "        \n",
    "        self.ref_is_hap = not(\"|\" in self.reference_panel.iloc[0, sample_value_index] or \"/\"  in self.reference_panel.iloc[0, sample_value_index])\n",
    "        self.ref_is_phased = \"|\" in self.reference_panel.iloc[0, sample_value_index] or self.ref_is_hap\n",
    "        ## For now I won't support merging haploids into unphased data\n",
    "        if self.ref_is_hap and not target_is_gonna_be_phased_or_haps:\n",
    "            raise ValueError(\"The reference contains haploids while the target will be unphased diploids. The model cannot predict the target at this rate.\")\n",
    "\n",
    "        if not self.ref_is_phased and target_is_gonna_be_phased_or_haps:\n",
    "            raise ValueError(\"The reference contains unphased diploids while the target will be phased or haploid data. The model cannot predict the target at this rate.\")\n",
    "\n",
    "        self.VARIANT_COUNT = self.reference_panel.shape[0]\n",
    "        print(f\"{self.VARIANT_COUNT} {'haplotype' if self.ref_is_hap else 'diplotype'} variants found!\")\n",
    "\n",
    "        self.is_phased = target_is_gonna_be_phased_or_haps and self.ref_is_phased\n",
    "        \n",
    "        allele_sep = \"|\" if self.ref_is_phased else \"/\"\n",
    "        def get_num_allels(g):\n",
    "            v1, v2 = g.split(allele_sep)\n",
    "            return max(int(v1), int(v2)) + 1\n",
    "\n",
    "        genotype_vals = np.unique(self.reference_panel.iloc[:, sample_value_index-1:].values)\n",
    "        if self.ref_is_phased and not target_is_gonna_be_phased_or_haps: # In this case ref is not haps\n",
    "            phased_to_unphased_dict = {}\n",
    "            for i in range(genotype_vals.shape[0]):\n",
    "                key = genotype_vals[i]\n",
    "                v1, v2 = [int(s) for s in genotype_vals[i].split(allele_sep)]\n",
    "                genotype_vals[i] = f\"{min(v1, v2)}{allele_sep}{max(v1, v2)}\"\n",
    "                phased_to_unphased_dict[key] = genotype_vals[i]\n",
    "            self.reference_panel.iloc[:, sample_value_index-1:].replace(phased_to_unphased_dict, inplace=True)\n",
    "\n",
    "        self.genotype_vals = np.unique(genotype_vals)\n",
    "\n",
    "        self.allele_count = max(map(get_num_allels, self.genotype_vals)) if not self.ref_is_hap else len(self.genotype_vals)\n",
    "        self.MISSING_VALUE = self.allele_count if self.is_phased else len(self.genotype_vals)\n",
    "\n",
    "        if self.is_phased:\n",
    "            self.hap_map = {str(i): i for i in range(self.allele_count)}\n",
    "            self.hap_map.update({\".\": self.allele_count})\n",
    "            self.r_hap_map = {i:k for k, i in self.hap_map.items()}\n",
    "            self.map_preds_2_allele = np.vectorize(lambda x: self.r_hap_map[x])\n",
    "\n",
    "        self.SEQ_DEPTH = self.allele_count + 1\n",
    "\n",
    "\n",
    "    def assign_test_set(self, file_path,\n",
    "                        variants_as_columns=False,\n",
    "                        delimiter=None,\n",
    "                        file_format=\"infer\",\n",
    "                        first_column_is_index=True,\n",
    "                        comments=\"##\") -> None:\n",
    "        \"\"\"\n",
    "        :param file_path: reference panel or the training file path. Currently, VCF, CSV, and TSV are supported\n",
    "        :param variants_as_columns: Whether the columns are variants and rows are samples or vice versa.\n",
    "        :param delimiter: the seperator used for the file\n",
    "        :param file_format: one of {\"vcf\", \"csv\", \"tsv\", \"infer\"}. If \"infer\" then the class will try to find the extension using the file name.\n",
    "        :param first_column_is_index: used for csv and tsv files to indicate if the first column should be used as identifier for samples/variants.\n",
    "        :param comments: The token to be used to filter out the lines indicating comments.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if self.reference_panel is None:\n",
    "            raise RuntimeError(\"First you need to use 'DataReader.assign_training_set(...) to assign a training set.' \")\n",
    "\n",
    "        sample_value_index = 2\n",
    "        target_file_extension, separator = self.find_file_extension(file_path, file_format, delimiter)\n",
    "\n",
    "        test_df = self.read_star_sv_files(file_path, is_reference=False, separator=separator, first_column_is_index=first_column_is_index, comments=comments) if self.training_file_extension != 'vcf' else self.read_star_sv_files(file_path, is_reference=False, separator='\\t', first_column_is_index=False, comments=\"##\")\n",
    "\n",
    "        if self.training_file_extension != \"vcf\":\n",
    "            if variants_as_columns:\n",
    "                test_df = test_df.transpose()\n",
    "            test_df.reset_index(inplace=True)\n",
    "            test_df.rename(columns={test_df.columns[0]: \"ID\"}, inplace=True)\n",
    "        else: # VCF\n",
    "            sample_value_index += 8\n",
    "\n",
    "        is_hap = not(\"|\" in test_df.iloc[0, sample_value_index] or \"/\"  in test_df.iloc[0, sample_value_index])\n",
    "        is_phased = \"|\" in test_df.iloc[0, sample_value_index]\n",
    "        if (is_hap or is_phased) and not self.ref_is_phased:\n",
    "            raise RuntimeError(\"\")\n",
    "\n",
    "        ALLELE_SEP = \"|\" if self.ref_is_phased else \"/\"\n",
    "\n",
    "        def key_gen(v1, v2):\n",
    "            return f\"{v1}{ALLELE_SEP}{v2}\"\n",
    "\n",
    "        self.genotype_keys = np.array([key_gen(i,j) for i in range(self.allele_count) for j in range(self.allele_count)]) if self.is_phased else self.genotype_vals\n",
    "        self.genotype_keys = np.hstack([self.genotype_keys, [\".|.\"] if self.is_phased else [\"./.\"]])\n",
    "        self.replacement_dict = {g:i for i,g in enumerate(self.genotype_keys)}\n",
    "        self.reverse_replacement_dict = {i:g for g,i in self.replacement_dict.items()}\n",
    "\n",
    "    def map_hap_2_ind_parent_1(self, x):\n",
    "        return self.hap_map[x.split('|')[0]]\n",
    "\n",
    "    def map_hap_2_ind_parent_2(self, x):\n",
    "        return self.hap_map[x.split('|')[1]]\n",
    "\n",
    "    def __get_forward_data(self, data: pd.DataFrame):\n",
    "        if self.is_phased:\n",
    "            # break it into haplotypes\n",
    "            _x = np.empty((data.shape[1] * 2, data.shape[0]), dtype=np.int32)\n",
    "\n",
    "            _x[0::2] = self.map_values_1_vec(data.values.T)\n",
    "            _x[1::2] = self.map_values_2_vec(data.values.T)\n",
    "            return _x\n",
    "        else:\n",
    "            return data.replace(self.replacement_dict).values.T.astype(np.int32)\n",
    "\n",
    "    def get_ref_set(self, starting_var_index=None, ending_var_index=None):\n",
    "        if starting_var_index>=0 and ending_var_index>=starting_var_index:\n",
    "            return self.__get_forward_data(self.reference_panel.iloc[starting_var_index:ending_var_index, 9:])\n",
    "        else:\n",
    "            print(\"No variant indices provided or indices not valid, using the whole sequence...\")\n",
    "            return self.__get_forward_data(self.reference_panel.iloc[:, 9:])\n",
    "\n",
    "    def get_target_set(self, starting_var_index=None, ending_var_index=None):\n",
    "        if starting_var_index>=0 and ending_var_index>=starting_var_index:\n",
    "            return self.__get_forward_data(self.target_set.iloc[starting_var_index:ending_var_index, 9:])\n",
    "        else:\n",
    "            print(\"No variant indices provided or indices not valid, using the whole sequence...\")\n",
    "            return self.__get_forward_data(self.target_set.iloc[:, 9:])\n",
    "\n",
    "    def convert_haps_to_genotypes(self, allele_probs):\n",
    "      '''output format: GT:DS:GP'''\n",
    "      FORMAT = \"GT:DS:GP\"\n",
    "      n_haploids, n_variants, n_alleles = allele_probs.shape\n",
    "      allele_probs_normalized = softmax(allele_probs, axis=-1)\n",
    "\n",
    "      if n_haploids % 2 != 0:\n",
    "          raise ValueError(\"Number of haploids should be even.\")\n",
    "\n",
    "      n_samples = n_haploids // 2\n",
    "      genotypes = np.zeros((n_samples, n_variants), dtype=object)\n",
    "\n",
    "      for i in tqdm(range(n_samples)):\n",
    "        haploid_1 = allele_probs_normalized[2 * i]\n",
    "        haploid_2 = allele_probs_normalized[2 * i + 1]\n",
    "\n",
    "        for j in range(n_variants):\n",
    "          phased_probs = np.multiply.outer(haploid_1[j], haploid_2[j]).flatten()\n",
    "          unphased_probs = np.array([phased_probs[0], sum(phased_probs[1:3]), phased_probs[-1]])\n",
    "          unphased_probs_str = \",\".join([f\"{v:.6f}\" for v in unphased_probs])\n",
    "          alt_dosage = np.dot(unphased_probs, [0, 1, 2])\n",
    "          variant_genotypes = [str(v) for v in np.argmax(allele_probs_normalized[i*2:(i+1)*2, j], axis=-1)]\n",
    "          genotypes[i, j] = '|'.join(variant_genotypes) + f\":{alt_dosage:.3f}:{unphased_probs_str}\"\n",
    "\n",
    "      new_vcf = self.target_set.copy()\n",
    "      new_vcf.iloc[:n_variants, 9:] = genotypes.T\n",
    "      new_vcf[\"FORMAT\"] = FORMAT\n",
    "      new_vcf[\"QUAL\"] = \".\"\n",
    "      new_vcf[\"FILTER\"] = \".\"\n",
    "      new_vcf[\"INFO\"] = \"IMPUTED\"\n",
    "      return new_vcf\n",
    "\n",
    "    def convert_unphased_probs_to_genotypes(self, allele_probs):\n",
    "      '''output format: GT:DS:GP'''\n",
    "      FORMAT = \"GT:DS:GP\"\n",
    "      n_samples, n_variants, n_alleles = allele_probs.shape\n",
    "      allele_probs_normalized = softmax(allele_probs, axis=-1)\n",
    "      genotypes = np.zeros((n_samples, n_variants), dtype=object)\n",
    "\n",
    "      for i in tqdm(range(n_samples)):\n",
    "          for j in range(n_variants):\n",
    "              unphased_probs = allele_probs_normalized[i, j]\n",
    "              unphased_probs_str = \",\".join([f\"{v:.6f}\" for v in unphased_probs])\n",
    "              alt_dosage = np.dot(unphased_probs, [0, 1, 2])\n",
    "              variant_genotypes = np.vectorize(self.reverse_replacement_dict.get)(np.argmax(unphased_probs, axis=-1)).flatten()\n",
    "              genotypes[i, j] = '/'.join(variant_genotypes) + f\":{unphased_probs_str}:{alt_dosage:.3f}\"\n",
    "\n",
    "      new_vcf = self.target_set.copy()\n",
    "      new_vcf.iloc[:, 9:] = genotypes.T\n",
    "      new_vcf[\"FORMAT\"] = FORMAT\n",
    "      new_vcf[\"QUAL\"] = \".\"\n",
    "      new_vcf[\"FILTER\"] = \".\"\n",
    "      new_vcf[\"INFO\"] = \"IMPUTED\"\n",
    "      return new_vcf\n",
    "\n",
    "    def __get_headers_for_output(self):\n",
    "      headers = [\"##fileformat=VCFv4.2\",\n",
    "           '''##source=STI v1.0.0''',\n",
    "           '''##INFO=<ID=IMPUTED,Number=0,Type=Flag,Description=\"Marker was imputed\">''',\n",
    "           '''##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">''',\n",
    "           '''##FORMAT=<ID=DS,Number=A,Type=Float,Description=\"Estimated Alternate Allele Dosage : [P(0/1)+2*P(1/1)]\">''',\n",
    "           '''##FORMAT=<ID=GP,Number=G,Type=Float,Description=\"Estimated Posterior Probabilities for Genotypes 0/0, 0/1 and 1/1\">''']\n",
    "      return headers\n",
    "\n",
    "    def preds_to_genotypes(self, preds):\n",
    "        \"\"\"\n",
    "        WARNING: This only supports bi-allelic data right now!\n",
    "        :param preds: numpy array of (n_samples, n_variants, n_alleles)\n",
    "        :return: numpy array of the same shape, with genotype calls, e.g., \"0/1\"\n",
    "        \"\"\"\n",
    "        if self.is_phased:\n",
    "          return self.convert_haps_to_genotypes(preds)\n",
    "        else:\n",
    "          return self.convert_unphased_probs_to_genotypes(preds)\n",
    "\n",
    "    def write_ligated_results_to_vcf(self, df, file_name):\n",
    "      with gzip.open(file_name, 'wt') if file_name.endswith(\".gz\") else open(file_name, 'wt') as f_out:\n",
    "          # write info\n",
    "          f_out.write(\"\\n\".join(self.__get_headers_for_output())+\"\\n\")\n",
    "      df.to_csv(file_name, sep=\"\\t\", mode='a', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:13:44.973215200Z",
     "start_time": "2023-09-13T16:13:44.850216400Z"
    }
   },
   "id": "addd78d2ffdfdbf0"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the file...\n"
     ]
    },
    {
     "data": {
      "text/plain": "    #CHROM       POS                       ID REF    ALT QUAL FILTER  \\\n0       22  16533236              SI_BD_17525   C  <CN0>  100   PASS   \n1       22  16577743           YL_CN_CEU_5170   T  <CN0>  100   PASS   \n2       22  16589908              SI_BD_17528   T  <CN0>  100   PASS   \n3       22  16633635           YL_CN_STU_4360   G  <CN0>  100   PASS   \n4       22  16940402   BI_GS_DEL1_B2_P2862_55   A  <CN0>  100   PASS   \n..     ...       ...                      ...  ..    ...  ...    ...   \n568     22  50808793  BI_GS_DEL1_B5_P2896_582   T  <CN0>  100   PASS   \n569     22  50975825  BI_GS_DEL1_B2_P2896_693   A  <CN0>  100   PASS   \n570     22  51054942              UW_VH_22595   T  <CN0>  100   PASS   \n571     22  51163690  BI_GS_DEL1_B2_P2897_127   C  <CN0>  100   PASS   \n572     22  51179178   BI_GS_DEL1_B4_P2897_43   A  <CN0>  100   PASS   \n\n                                                  INFO FORMAT HG00096  ...  \\\n0    AC=125;AF=0.0249601;AFR_AF=0.09;AMR_AF=0.0086;...     GT     0|0  ...   \n1    AC=29;AF=0.00579073;AFR_AF=0.0098;AMR_AF=0.001...     GT     0|0  ...   \n2    AC=186;AF=0.0371406;AFR_AF=0.1021;AMR_AF=0.014...     GT     0|0  ...   \n3    AC=2;AF=0.00039936;AFR_AF=0;AMR_AF=0;AN=5008;C...     GT     0|0  ...   \n4    AC=2;AF=0.00039936;AFR_AF=0;AMR_AF=0;AN=5008;C...     GT     0|0  ...   \n..                                                 ...    ...     ...  ...   \n568  AC=3;AF=0.00059904;AFR_AF=0.0023;AMR_AF=0;AN=5...     GT     0|0  ...   \n569  AC=118;AF=0.0235623;AFR_AF=0.087;AMR_AF=0.0043...     GT     0|0  ...   \n570  AC=1;AF=0.00019968;AFR_AF=0;AMR_AF=0;AN=5008;C...     GT     0|0  ...   \n571  AC=1;AF=0.00019968;AFR_AF=0;AMR_AF=0;AN=5008;C...     GT     0|0  ...   \n572  AC=1;AF=0.00019968;AFR_AF=0.0008;AMR_AF=0;AN=5...     GT     0|0  ...   \n\n    NA21128 NA21129 NA21130 NA21133 NA21135 NA21137 NA21141 NA21142 NA21143  \\\n0       0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0   \n1       0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0   \n2       0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0   \n3       0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0   \n4       0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0   \n..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n568     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0   \n569     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0   \n570     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0   \n571     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0   \n572     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0     0|0   \n\n    NA21144  \n0       0|0  \n1       0|0  \n2       0|0  \n3       0|0  \n4       0|0  \n..      ...  \n568     0|0  \n569     0|0  \n570     0|0  \n571     0|0  \n572     0|0  \n\n[573 rows x 2513 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#CHROM</th>\n      <th>POS</th>\n      <th>ID</th>\n      <th>REF</th>\n      <th>ALT</th>\n      <th>QUAL</th>\n      <th>FILTER</th>\n      <th>INFO</th>\n      <th>FORMAT</th>\n      <th>HG00096</th>\n      <th>...</th>\n      <th>NA21128</th>\n      <th>NA21129</th>\n      <th>NA21130</th>\n      <th>NA21133</th>\n      <th>NA21135</th>\n      <th>NA21137</th>\n      <th>NA21141</th>\n      <th>NA21142</th>\n      <th>NA21143</th>\n      <th>NA21144</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22</td>\n      <td>16533236</td>\n      <td>SI_BD_17525</td>\n      <td>C</td>\n      <td>&lt;CN0&gt;</td>\n      <td>100</td>\n      <td>PASS</td>\n      <td>AC=125;AF=0.0249601;AFR_AF=0.09;AMR_AF=0.0086;...</td>\n      <td>GT</td>\n      <td>0|0</td>\n      <td>...</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22</td>\n      <td>16577743</td>\n      <td>YL_CN_CEU_5170</td>\n      <td>T</td>\n      <td>&lt;CN0&gt;</td>\n      <td>100</td>\n      <td>PASS</td>\n      <td>AC=29;AF=0.00579073;AFR_AF=0.0098;AMR_AF=0.001...</td>\n      <td>GT</td>\n      <td>0|0</td>\n      <td>...</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22</td>\n      <td>16589908</td>\n      <td>SI_BD_17528</td>\n      <td>T</td>\n      <td>&lt;CN0&gt;</td>\n      <td>100</td>\n      <td>PASS</td>\n      <td>AC=186;AF=0.0371406;AFR_AF=0.1021;AMR_AF=0.014...</td>\n      <td>GT</td>\n      <td>0|0</td>\n      <td>...</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22</td>\n      <td>16633635</td>\n      <td>YL_CN_STU_4360</td>\n      <td>G</td>\n      <td>&lt;CN0&gt;</td>\n      <td>100</td>\n      <td>PASS</td>\n      <td>AC=2;AF=0.00039936;AFR_AF=0;AMR_AF=0;AN=5008;C...</td>\n      <td>GT</td>\n      <td>0|0</td>\n      <td>...</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22</td>\n      <td>16940402</td>\n      <td>BI_GS_DEL1_B2_P2862_55</td>\n      <td>A</td>\n      <td>&lt;CN0&gt;</td>\n      <td>100</td>\n      <td>PASS</td>\n      <td>AC=2;AF=0.00039936;AFR_AF=0;AMR_AF=0;AN=5008;C...</td>\n      <td>GT</td>\n      <td>0|0</td>\n      <td>...</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>22</td>\n      <td>50808793</td>\n      <td>BI_GS_DEL1_B5_P2896_582</td>\n      <td>T</td>\n      <td>&lt;CN0&gt;</td>\n      <td>100</td>\n      <td>PASS</td>\n      <td>AC=3;AF=0.00059904;AFR_AF=0.0023;AMR_AF=0;AN=5...</td>\n      <td>GT</td>\n      <td>0|0</td>\n      <td>...</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n    </tr>\n    <tr>\n      <th>569</th>\n      <td>22</td>\n      <td>50975825</td>\n      <td>BI_GS_DEL1_B2_P2896_693</td>\n      <td>A</td>\n      <td>&lt;CN0&gt;</td>\n      <td>100</td>\n      <td>PASS</td>\n      <td>AC=118;AF=0.0235623;AFR_AF=0.087;AMR_AF=0.0043...</td>\n      <td>GT</td>\n      <td>0|0</td>\n      <td>...</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n    </tr>\n    <tr>\n      <th>570</th>\n      <td>22</td>\n      <td>51054942</td>\n      <td>UW_VH_22595</td>\n      <td>T</td>\n      <td>&lt;CN0&gt;</td>\n      <td>100</td>\n      <td>PASS</td>\n      <td>AC=1;AF=0.00019968;AFR_AF=0;AMR_AF=0;AN=5008;C...</td>\n      <td>GT</td>\n      <td>0|0</td>\n      <td>...</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n    </tr>\n    <tr>\n      <th>571</th>\n      <td>22</td>\n      <td>51163690</td>\n      <td>BI_GS_DEL1_B2_P2897_127</td>\n      <td>C</td>\n      <td>&lt;CN0&gt;</td>\n      <td>100</td>\n      <td>PASS</td>\n      <td>AC=1;AF=0.00019968;AFR_AF=0;AMR_AF=0;AN=5008;C...</td>\n      <td>GT</td>\n      <td>0|0</td>\n      <td>...</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n    </tr>\n    <tr>\n      <th>572</th>\n      <td>22</td>\n      <td>51179178</td>\n      <td>BI_GS_DEL1_B4_P2897_43</td>\n      <td>A</td>\n      <td>&lt;CN0&gt;</td>\n      <td>100</td>\n      <td>PASS</td>\n      <td>AC=1;AF=0.00019968;AFR_AF=0.0008;AMR_AF=0;AN=5...</td>\n      <td>GT</td>\n      <td>0|0</td>\n      <td>...</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n      <td>0|0</td>\n    </tr>\n  </tbody>\n</table>\n<p>573 rows Ã— 2513 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataReader().read_star_sv_files(\"./data/STI_benchmark_datasets/DELL.chr22.genotypes.full.vcf.gz\", is_reference=False, separator=\"\\t\", first_column_is_index=False, comments=\"##\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:13:55.940328200Z",
     "start_time": "2023-09-13T16:13:49.227955200Z"
    }
   },
   "id": "fecfa6c805e681e8"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "0.08057642728090286"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "getsizeof(df)/(1024.0**3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:12:18.805398600Z",
     "start_time": "2023-09-13T16:12:18.515399900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "0.002566937357187271"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "getsizeof(df)/(1024.0**3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:13:56.105324500Z",
     "start_time": "2023-09-13T16:13:56.002323800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.iloc[0, 10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:14:17.394264100Z",
     "start_time": "2023-09-13T16:14:17.340262400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
